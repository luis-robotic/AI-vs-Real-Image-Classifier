{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e72cb46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "# ============== CONFIGURACIÓN ==============\n",
    "DATASET_PATH = r\"C:\\Users\\Usuario\\.cache\\kagglehub\\datasets\\philosopher0808\\real-vs-ai-generated-faces-dataset\\versions\\1\\dataset\\dataset\"\n",
    "IMG_SIZE = 224  # Tamaño óptimo para transfer learning\n",
    "BATCH_SIZE = 32\n",
    "NUM_CLASSES = 2\n",
    "EPOCHS = 50\n",
    "\n",
    "# ============== DATA GENERATORS ==============\n",
    "print(\"Configurando generadores de datos...\")\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest',\n",
    "    brightness_range=[0.8, 1.2]  # Variación de brillo\n",
    ")\n",
    "\n",
    "val_test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    directory=f\"{DATASET_PATH}/train\",\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_generator = val_test_datagen.flow_from_directory(\n",
    "    directory=f\"{DATASET_PATH}/validate\",\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "test_generator = val_test_datagen.flow_from_directory(\n",
    "    directory=f\"{DATASET_PATH}/test\",\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Guardar nombres de clases\n",
    "class_names = list(train_generator.class_indices.keys())\n",
    "print(f\"Clases detectadas: {class_names}\")\n",
    "print(f\"Total imágenes entrenamiento: {train_generator.samples}\")\n",
    "print(f\"Total imágenes validación: {val_generator.samples}\")\n",
    "print(f\"Total imágenes test: {test_generator.samples}\")\n",
    "\n",
    "# ============== CREAR MODELO CON TRANSFER LEARNING ==============\n",
    "print(\"\\nCreando modelo con MobileNetV2...\")\n",
    "\n",
    "# Cargar modelo base preentrenado\n",
    "base_model = tf.keras.applications.MobileNetV2(\n",
    "    input_shape=(IMG_SIZE, IMG_SIZE, 3),\n",
    "    include_top=False,\n",
    "    weights='imagenet'\n",
    ")\n",
    "\n",
    "# Congelar las capas del modelo base inicialmente\n",
    "base_model.trainable = False\n",
    "\n",
    "# Crear el modelo completo\n",
    "model = Sequential([\n",
    "    base_model,\n",
    "    GlobalAveragePooling2D(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(NUM_CLASSES, activation='softmax')\n",
    "], name='AI_Image_Detector')\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# ============== COMPILAR MODELO ==============\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    metrics=['accuracy', tf.keras.metrics.AUC(name='auc')]\n",
    ")\n",
    "\n",
    "# ============== CALLBACKS ==============\n",
    "callbacks = [\n",
    "    # Detener si no mejora en 7 épocas\n",
    "    EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=7,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    # Guardar el mejor modelo\n",
    "    ModelCheckpoint(\n",
    "        'best_model.keras',\n",
    "        monitor='val_accuracy',\n",
    "        save_best_only=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    # Reducir learning rate si se estanca\n",
    "    ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=3,\n",
    "        min_lr=1e-7,\n",
    "        verbose=1\n",
    "    )\n",
    "]\n",
    "\n",
    "# ============== ENTRENAMIENTO ==============\n",
    "print(\"\\n========== FASE 1: Entrenamiento con capas congeladas ==========\")\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=20,\n",
    "    validation_data=val_generator,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# ============== FINE-TUNING ==============\n",
    "print(\"\\n========== FASE 2: Fine-tuning (descongelando capas) ==========\")\n",
    "\n",
    "# Descongelar las últimas capas del modelo base\n",
    "base_model.trainable = True\n",
    "\n",
    "# Congelar solo las primeras capas\n",
    "for layer in base_model.layers[:100]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Recompilar con learning rate más bajo\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "    metrics=['accuracy', tf.keras.metrics.AUC(name='auc')]\n",
    ")\n",
    "\n",
    "# Continuar entrenamiento\n",
    "history_fine = model.fit(\n",
    "    train_generator,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=val_generator,\n",
    "    callbacks=callbacks,\n",
    "    initial_epoch=len(history.history['loss']),\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Combinar historiales\n",
    "for key in history.history.keys():\n",
    "    history.history[key].extend(history_fine.history[key])\n",
    "\n",
    "# ============== EVALUACIÓN ==============\n",
    "print(\"\\n========== EVALUACIÓN EN TEST SET ==========\")\n",
    "test_loss, test_acc, test_auc = model.evaluate(test_generator)\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {test_acc:.4f}\")\n",
    "print(f\"Test AUC: {test_auc:.4f}\")\n",
    "\n",
    "# Guardar modelo final\n",
    "model.save('final_model.keras')\n",
    "print(\"\\nModelo guardado como 'final_model.keras'\")\n",
    "\n",
    "# ============== VISUALIZACIÓN DE RESULTADOS ==============\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Accuracy\n",
    "axes[0].plot(history.history['accuracy'], 'b', label='Train')\n",
    "axes[0].plot(history.history['val_accuracy'], 'r', label='Validation')\n",
    "axes[0].set_xlabel('Épocas')\n",
    "axes[0].set_ylabel('Accuracy')\n",
    "axes[0].set_title('Accuracy durante entrenamiento')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True)\n",
    "\n",
    "# Loss\n",
    "axes[1].plot(history.history['loss'], 'b', label='Train')\n",
    "axes[1].plot(history.history['val_loss'], 'r', label='Validation')\n",
    "axes[1].set_xlabel('Épocas')\n",
    "axes[1].set_ylabel('Loss')\n",
    "axes[1].set_title('Loss durante entrenamiento')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('training_history.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# ============== FUNCIÓN DE PREDICCIÓN ==============\n",
    "def predict_image(img_path, model, class_names):\n",
    "    \"\"\"\n",
    "    Predice si una imagen es real o generada por IA\n",
    "    \n",
    "    Args:\n",
    "        img_path: Ruta de la imagen\n",
    "        model: Modelo entrenado\n",
    "        class_names: Lista con nombres de las clases\n",
    "        \n",
    "    Returns:\n",
    "        predicted_class: Clase predicha\n",
    "        confidence: Confianza de la predicción (%)\n",
    "    \"\"\"\n",
    "    # Cargar y preprocesar imagen\n",
    "    img = image.load_img(img_path, target_size=(IMG_SIZE, IMG_SIZE))\n",
    "    img_array = image.img_to_array(img) / 255.0\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    \n",
    "    # Predecir\n",
    "    prediction = model.predict(img_array, verbose=0)\n",
    "    predicted_idx = np.argmax(prediction)\n",
    "    predicted_class = class_names[predicted_idx]\n",
    "    confidence = prediction[0][predicted_idx] * 100\n",
    "    \n",
    "    # Visualizar\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(img)\n",
    "    plt.title(f\"Predicción: {predicted_class}\\nConfianza: {confidence:.2f}%\", \n",
    "              fontsize=14, fontweight='bold')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # Añadir barra de probabilidades\n",
    "    plt.text(10, img.size[1] - 10, \n",
    "             f\"{class_names[0]}: {prediction[0][0]*100:.1f}%\\n{class_names[1]}: {prediction[0][1]*100:.1f}%\",\n",
    "             bbox=dict(boxstyle='round', facecolor='white', alpha=0.8),\n",
    "             fontsize=10)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Imagen: {img_path}\")\n",
    "    print(f\"Predicción: {predicted_class}\")\n",
    "    print(f\"Confianza: {confidence:.2f}%\")\n",
    "    print(f\"Probabilidades detalladas:\")\n",
    "    for i, class_name in enumerate(class_names):\n",
    "        print(f\"  - {class_name}: {prediction[0][i]*100:.2f}%\")\n",
    "    print(f\"{'='*50}\\n\")\n",
    "    \n",
    "    return predicted_class, confidence\n",
    "\n",
    "# ============== PREDICCIONES DE EJEMPLO ==============\n",
    "print(\"\\n========== PREDICCIONES EN IMÁGENES DE PRUEBA ==========\")\n",
    "\n",
    "# Lista de imágenes a probar\n",
    "test_images = [\n",
    "    r\"C:\\Users\\Usuario\\Downloads\\IA1.jpg\",\n",
    "    r\"C:\\Users\\Usuario\\Downloads\\IA2.jpg\",\n",
    "    r\"C:\\Users\\Usuario\\Downloads\\IA3.jpg\",\n",
    "    r\"C:\\Users\\Usuario\\Downloads\\IA4.jpg\"\n",
    "]\n",
    "\n",
    "# Predecir cada imagen\n",
    "results = []\n",
    "for img_path in test_images:\n",
    "    try:\n",
    "        predicted_class, confidence = predict_image(img_path, model, class_names)\n",
    "        results.append({\n",
    "            'path': img_path,\n",
    "            'prediction': predicted_class,\n",
    "            'confidence': confidence\n",
    "        })\n",
    "    except Exception as e:\n",
    "        print(f\"Error al procesar {img_path}: {e}\")\n",
    "\n",
    "# Resumen de resultados\n",
    "print(\"\\n========== RESUMEN DE PREDICCIONES ==========\")\n",
    "for i, result in enumerate(results, 1):\n",
    "    print(f\"{i}. {result['path'].split('\\\\')[-1]}: {result['prediction']} ({result['confidence']:.2f}%)\")\n",
    "\n",
    "print(\"\\n✓ Proceso completado exitosamente\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "proyectoIA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
