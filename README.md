# AI-vs-Real-Image-Classifier
El objetivo de este proyecto es desarrollar un modelo de Inteligencia Artificial capaz de clasificar imÃ¡genes en dos categorÃ­as: imÃ¡genes generadas por IA e imÃ¡genes no generadas por IA (reales).

## NOTAS Github
url: https://github.com/luis-robotic/AI-vs-Real-Image-Classifier.git

Cada vez que hagas cambios:

git add .
git commit -m "DescripciÃ³n del cambio"
git push origin main

#### Descargar el dataset:

import kagglehub

<!-- Download latest version -->
path = kagglehub.dataset_download("philosopher0808/real-vs-ai-generated-faces-dataset")

print("Path to dataset files:", path)


#### Ruta:
C:\Users\Usuario\.cache\kagglehub\datasets\
â””â”€â”€ philosopher0808\
    â””â”€â”€ real-vs-ai-generated-faces-dataset\
        â””â”€â”€ versions\
            â””â”€â”€ 1\
                â””â”€â”€ dataset\
                    â””â”€â”€ dataset\

##### Estructura completa del dataset

dataset/
â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ 0/
â”‚   â”‚   â”œâ”€â”€ img_0001.jpg
â”‚   â”‚   â”œâ”€â”€ img_0002.jpg
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”‚
â”‚   â””â”€â”€ 1/
â”‚       â”œâ”€â”€ img_0001.jpg
â”‚       â”œâ”€â”€ img_0002.jpg
â”‚       â””â”€â”€ ...
â”‚
â”œâ”€â”€ validate/
â”‚   â”œâ”€â”€ 0/
â”‚   â”‚   â”œâ”€â”€ img_0001.jpg
â”‚   â”‚   â”œâ”€â”€ img_0002.jpg
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”‚
â”‚   â””â”€â”€ 1/
â”‚       â”œâ”€â”€ img_0001.jpg
â”‚       â”œâ”€â”€ img_0002.jpg
â”‚       â””â”€â”€ ...
â”‚
â””â”€â”€ test/
    â”œâ”€â”€ 0/
    â”‚   â”œâ”€â”€ img_0001.jpg
    â”‚   â”œâ”€â”€ img_0002.jpg
    â”‚   â””â”€â”€ ...
    â”‚
    â””â”€â”€ 1/
        â”œâ”€â”€ img_0001.jpg
        â”œâ”€â”€ img_0002.jpg
        â””â”€â”€ ...




# Real vs AI-Generated Faces Classification

## DescripciÃ³n del Proyecto
Este proyecto tiene como objetivo desarrollar un **clasificador binario de imÃ¡genes** que pueda distinguir entre **rostros reales** y **rostros generados por inteligencia artificial**. El proyecto utiliza **Deep Learning** y arquitecturas de redes convolucionales (CNN) para identificar patrones y artefactos presentes en imÃ¡genes sintÃ©ticas, incluyendo generadas por GANs, diffusion models y tÃ©cnicas de faceswap.

---

## MotivaciÃ³n
Con la proliferaciÃ³n de generadores de imÃ¡genes basados en IA, detectar imÃ¡genes sintÃ©ticas se ha vuelto crÃ­tico en Ã¡reas como:

- Seguridad y detecciÃ³n de deepfakes
- Periodismo y verificaciÃ³n de medios
- InvestigaciÃ³n en visiÃ³n por computadora

El proyecto busca explorar **cÃ³mo las redes CNN pueden aprender a diferenciar imÃ¡genes reales de las generadas**, evaluando precisiÃ³n, recall, F1-score y otras mÃ©tricas relevantes.

---

## Dataset

### Fuente
- Kaggle: [Real vs AI Generated Faces Dataset](https://www.kaggle.com/datasets/philosopher0808/real-vs-ai-generated-faces-dataset)
- El dataset contiene imÃ¡genes de rostros reales (FFHQ) y rostros generados por IA de mÃºltiples fuentes (StyleGAN, Stable Diffusion, faceswap, ThisPersonDoesNotExist).

### Estructura
El dataset descargado ya viene organizado en:

dataset/
â”œâ”€â”€ train/
â”‚ â”œâ”€â”€ 0/ â† imÃ¡genes reales
â”‚ â””â”€â”€ 1/ â† imÃ¡genes generadas por IA
â”œâ”€â”€ validate/
â”‚ â”œâ”€â”€ 0/
â”‚ â””â”€â”€ 1/
â””â”€â”€ test/
â”œâ”€â”€ 0/
â””â”€â”€ 1/


- Cada subcarpeta contiene imÃ¡genes `.jpg`
- La separaciÃ³n `train`, `validate` y `test` permite entrenar y evaluar sin necesidad de dividir manualmente los datos.

---

## Preprocesamiento de ImÃ¡genes
Para asegurar consistencia durante el entrenamiento:

- Todas las imÃ¡genes se cargan en **RGB**
- Se redimensionan a **128Ã—128 pÃ­xeles** (configurable)
- Se normalizan los valores de pÃ­xel a `[0,1]`
- Data augmentation opcional:
  - Flip horizontal
  - RotaciÃ³n ligera
  - Ajuste de brillo / contraste

---

## Arquitectura del Modelo

- Se puede usar una **CNN desde cero**:
  - Varias capas `Conv2D` + `ReLU` + `MaxPooling`
  - Flatten â†’ Dense â†’ Output `sigmoid`
- O **Transfer Learning** con modelos preentrenados como:
  - ResNet50
  - MobileNetV2
  - EfficientNet
- FunciÃ³n de pÃ©rdida: **Binary Cross-Entropy**
- Optimizador: **Adam**
- MÃ©tricas:
  - Accuracy
  - Precision / Recall
  - F1-score
  - ROC-AUC

---

## Entrenamiento

- Split original del dataset: `train / validate / test`
- Batch size recomendado: 16â€“32
- Early stopping basado en pÃ©rdida de validaciÃ³n
- Learning rate scheduler opcional para mejorar convergencia
- Entrenamiento en GPU recomendado si se dispone

---

## EvaluaciÃ³n

- Se analiza la **matriz de confusiÃ³n** para identificar falsos positivos y falsos negativos
- Se calcula **accuracy, F1-score y ROC-AUC**
- Se pueden usar herramientas como **Grad-CAM** para visualizar quÃ© Ã¡reas de la imagen influyen en la decisiÃ³n del modelo

---

## Uso del Proyecto

1. Clonar repositorio:
<!-- ```bash -->
git clone <REPO_URL>


2. Crear entorno virtual (recomendado):

conda create -n ia_faces python=3.10
conda activate ia_faces


3. Instalar dependencias:

pip install -r requirements.txt


4. Ejecutar notebooks:

01_exploracion_dataset.ipynb

02_preprocesado.ipynb

03_entrenamiento.ipynb


IA_faces_project/
â”œâ”€â”€ data/                     # Dataset descargado
â”‚   â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ validate/
â”‚   â””â”€â”€ test/
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_exploracion_dataset.ipynb
â”‚   â”œâ”€â”€ 02_preprocesado.ipynb
â”‚   â””â”€â”€ 03_entrenamiento.ipynb
â”œâ”€â”€ src/                      # Scripts de carga de datos y modelos
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md


Consideraciones y Limitaciones

El modelo puede detectar patrones especÃ­ficos de los generadores incluidos en el dataset, pero puede fallar en nuevos generadores no vistos.

Sensible a postprocesado (blur, resize, filtros)

Se recomienda evaluar con datasets externos para validar generalizaciÃ³n

Extensiones Futuras

ClasificaciÃ³n multiclase segÃºn tipo de generador

Uso de anÃ¡lisis en frecuencia (Fourier) para detectar artefactos

Ensembles de CNNs para mejorar precisiÃ³n

VisualizaciÃ³n de Ã¡reas crÃ­ticas con Grad-CAM o saliency maps

Referencias

FFHQ: https://github.com/NVlabs/ffhq-dataset

StyleGAN / GANs: Karras et al., 2019

Stable Diffusion: https://stability.ai/blog/stable-diffusion-public-release

Kaggle Dataset: Real vs AI Generated Faces Dataset





# w-------------------------------------------------------------------

ğŸ­ Real vs AI-Generated Faces Classification
Mostrar imagen
Mostrar imagen
Mostrar imagen

Un clasificador binario basado en Deep Learning para distinguir entre rostros reales y rostros generados por inteligencia artificial.

ğŸ“‹ Tabla de Contenidos
DescripciÃ³n
MotivaciÃ³n
Dataset
InstalaciÃ³n
Estructura del Proyecto
Preprocesamiento
Arquitectura del Modelo
Entrenamiento
EvaluaciÃ³n
Resultados
Limitaciones
Trabajo Futuro
Referencias
Licencia
ğŸ¯ DescripciÃ³n
Este proyecto implementa un clasificador binario de imÃ¡genes utilizando redes neuronales convolucionales (CNN) para identificar patrones y artefactos presentes en rostros sintÃ©ticos generados por:

GANs (StyleGAN, ThisPersonDoesNotExist)
Modelos de difusiÃ³n (Stable Diffusion)
TÃ©cnicas de faceswap
ğŸ’¡ MotivaciÃ³n
La detecciÃ³n de imÃ¡genes sintÃ©ticas es crÃ­tica en mÃºltiples Ã¡reas:

ğŸ”’ Seguridad: DetecciÃ³n de deepfakes y fraude de identidad
ğŸ“° Periodismo: VerificaciÃ³n de autenticidad de medios
ğŸ”¬ InvestigaciÃ³n: Avances en visiÃ³n por computadora y detecciÃ³n de manipulaciÃ³n
Este proyecto explora cÃ³mo las CNNs pueden aprender a diferenciar rostros reales de generados, evaluando mÃ©tricas como accuracy, precision, recall, F1-score y ROC-AUC.

ğŸ“Š Dataset
Fuente
Kaggle: Real vs AI Generated Faces Dataset

El dataset combina:

Rostros reales: FFHQ (Flickr-Faces-HQ)
Rostros sintÃ©ticos: StyleGAN, Stable Diffusion, faceswap, ThisPersonDoesNotExist
Estructura
dataset/
â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ 0/          # ImÃ¡genes reales
â”‚   â””â”€â”€ 1/          # ImÃ¡genes generadas por IA
â”œâ”€â”€ validate/
â”‚   â”œâ”€â”€ 0/
â”‚   â””â”€â”€ 1/
â””â”€â”€ test/
    â”œâ”€â”€ 0/
    â””â”€â”€ 1/
CaracterÃ­sticas:

Formato: .jpg
DivisiÃ³n predefinida en train/validate/test
Clases balanceadas
ğŸš€ InstalaciÃ³n
Requisitos Previos
Python 3.10 o superior
GPU recomendada para entrenamiento (opcional)
Pasos
Clonar el repositorio:
bash
git clone https://github.com/tu-usuario/ia-faces-classification.git
cd ia-faces-classification
Crear entorno virtual (recomendado):
bash
# Con conda
conda create -n ia_faces python=3.10
conda activate ia_faces

# O con venv
python -m venv venv
source venv/bin/activate  # Linux/Mac
venv\Scripts\activate     # Windows
Instalar dependencias:
bash
pip install -r requirements.txt
Descargar el dataset:
bash
# Usando Kaggle API
kaggle datasets download -d philosopher0808/real-vs-ai-generated-faces-dataset
unzip real-vs-ai-generated-faces-dataset.zip -d data/
ğŸ“ Estructura del Proyecto
IA_faces_project/
â”œâ”€â”€ data/                           # Dataset (no incluido en repo)
â”‚   â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ validate/
â”‚   â””â”€â”€ test/
â”œâ”€â”€ notebooks/                      # Jupyter notebooks
â”‚   â”œâ”€â”€ 01_exploracion_dataset.ipynb
â”‚   â”œâ”€â”€ 02_preprocesado.ipynb
â”‚   â”œâ”€â”€ 03_entrenamiento.ipynb
â”‚   â””â”€â”€ 04_evaluacion.ipynb
â”œâ”€â”€ src/                            # CÃ³digo fuente
â”‚   â”œâ”€â”€ data_loader.py             # Carga y preparaciÃ³n de datos
â”‚   â”œâ”€â”€ models.py                  # Arquitecturas CNN
â”‚   â”œâ”€â”€ train.py                   # Script de entrenamiento
â”‚   â”œâ”€â”€ evaluate.py                # EvaluaciÃ³n del modelo
â”‚   â””â”€â”€ utils.py                   # Funciones auxiliares
â”œâ”€â”€ models/                         # Modelos entrenados (checkpoints)
â”œâ”€â”€ results/                        # MÃ©tricas y visualizaciones
â”œâ”€â”€ requirements.txt                # Dependencias del proyecto
â”œâ”€â”€ README.md                       # Este archivo
â””â”€â”€ LICENSE                         # Licencia del proyecto
ğŸ”§ Preprocesamiento
Transformaciones aplicadas a las imÃ¡genes:

ConversiÃ³n a RGB: NormalizaciÃ³n del espacio de color
Redimensionamiento: 128Ã—128 pÃ­xeles (configurable)
NormalizaciÃ³n: Valores de pÃ­xel escalados a [0, 1]
Data Augmentation (opcional)
Flip horizontal aleatorio
RotaciÃ³n ligera (Â±15Â°)
Ajuste de brillo y contraste
Zoom aleatorio
python
# Ejemplo de configuraciÃ³n
IMG_SIZE = 128
BATCH_SIZE = 32
AUGMENTATION = True
ğŸ§  Arquitectura del Modelo
OpciÃ³n 1: CNN Personalizada
Conv2D(32) â†’ ReLU â†’ MaxPooling
Conv2D(64) â†’ ReLU â†’ MaxPooling
Conv2D(128) â†’ ReLU â†’ MaxPooling
Flatten
Dense(256) â†’ ReLU â†’ Dropout(0.5)
Dense(1) â†’ Sigmoid
OpciÃ³n 2: Transfer Learning
Modelos preentrenados disponibles:

ResNet50: Buena precisiÃ³n, computacionalmente intensivo
MobileNetV2: Ligero, ideal para deployment
EfficientNetB0: Balance entre precisiÃ³n y eficiencia
ConfiguraciÃ³n de Entrenamiento
FunciÃ³n de pÃ©rdida: Binary Cross-Entropy
Optimizador: Adam (lr=0.001)
MÃ©tricas: Accuracy, Precision, Recall, F1-Score, ROC-AUC
ğŸ‹ï¸ Entrenamiento
EjecuciÃ³n con Script
bash
python src/train.py --model resnet50 --epochs 50 --batch-size 32
EjecuciÃ³n con Notebooks
Abre y ejecuta secuencialmente:

01_exploracion_dataset.ipynb - AnÃ¡lisis exploratorio
02_preprocesado.ipynb - PreparaciÃ³n de datos
03_entrenamiento.ipynb - Entrenamiento del modelo
04_evaluacion.ipynb - EvaluaciÃ³n y visualizaciÃ³n
HiperparÃ¡metros Recomendados
ParÃ¡metro	Valor
Batch size	16-32
Ã‰pocas	30-50
Learning rate	0.001
Early stopping patience	5-10
Callbacks utilizados:

Early Stopping (monitor: val_loss)
ModelCheckpoint (guarda mejor modelo)
ReduceLROnPlateau (ajuste dinÃ¡mico de lr)
ğŸ“ˆ EvaluaciÃ³n
MÃ©tricas Calculadas
Accuracy: PrecisiÃ³n general del modelo
Precision/Recall: Por clase (real/fake)
F1-Score: Media armÃ³nica precision-recall
ROC-AUC: Ãrea bajo la curva ROC
Matriz de ConfusiÃ³n: AnÃ¡lisis de errores
Visualizaciones
Curvas de entrenamiento (loss/accuracy)
Matriz de confusiÃ³n
Curva ROC
Grad-CAM: Mapas de calor de activaciÃ³n
Ejemplos de predicciones correctas/incorrectas
Ejemplo de EvaluaciÃ³n
bash
python src/evaluate.py --model models/best_model.h5 --test-dir data/test/
ğŸ¯ Resultados
Nota: Completa esta secciÃ³n despuÃ©s del entrenamiento

MÃ©trica	Valor
Test Accuracy	TBD
Precision (Real)	TBD
Precision (Fake)	TBD
Recall (Real)	TBD
Recall (Fake)	TBD
F1-Score	TBD
ROC-AUC	TBD
Observaciones
[Incluye anÃ¡lisis de errores comunes]
[Tipos de imÃ¡genes mÃ¡s difÃ­ciles de clasificar]
[ComparaciÃ³n entre arquitecturas probadas]
âš ï¸ Limitaciones
GeneralizaciÃ³n limitada: El modelo puede detectar patrones especÃ­ficos de los generadores incluidos en el dataset, pero puede fallar con nuevos generadores no vistos durante el entrenamiento
Sensibilidad al postprocesado: El rendimiento puede degradarse con imÃ¡genes que han sido modificadas mediante blur, resize, compresiÃ³n JPEG o aplicaciÃ³n de filtros
EvoluciÃ³n de generadores: Los modelos generativos mejoran constantemente, lo que puede reducir la efectividad del clasificador con el tiempo
Dataset especÃ­fico: Entrenado principalmente con rostros frontales de alta calidad; el rendimiento puede variar con Ã¡ngulos diferentes, oclusiones o baja resoluciÃ³n
ğŸ”® Trabajo Futuro
Mejoras Propuestas
 ClasificaciÃ³n multiclase: Identificar el tipo especÃ­fico de generador (StyleGAN, Stable Diffusion, etc.)
 AnÃ¡lisis en frecuencia: Utilizar transformadas de Fourier para detectar artefactos espectrales
 Ensemble de modelos: Combinar mÃºltiples CNNs para mejorar robustez
 Explainability avanzada: Implementar Grad-CAM++ y saliency maps
 Dataset extendido: Evaluar con datasets externos (CelebA-HQ, Generated Faces)
 DetecciÃ³n en video: Extender a detecciÃ³n de deepfakes en secuencias
 Model deployment: API REST y aplicaciÃ³n web para clasificaciÃ³n en tiempo real
 Adversarial training: Mejorar resistencia a ataques adversarios
ğŸ“š Referencias
FFHQ Dataset: NVlabs/ffhq-dataset
StyleGAN: Karras et al. (2019) - "A Style-Based Generator Architecture for Generative Adversarial Networks"
Stable Diffusion: Stability AI Blog
Dataset Original: Kaggle - Real vs AI Generated Faces
Grad-CAM: Selvaraju et al. (2017) - "Grad-CAM: Visual Explanations from Deep Networks"
ArtÃ­culos Relacionados
Wang et al. (2020) - "CNN-generated images are surprisingly easy to spot... for now"
Gragnaniello et al. (2021) - "GAN-generated faces detection"
ğŸ“„ Licencia
Este proyecto estÃ¡ bajo la Licencia MIT. Ver el archivo LICENSE para mÃ¡s detalles.

ğŸ‘¥ Contribuciones
Las contribuciones son bienvenidas. Por favor:

Fork el proyecto
Crea una rama para tu feature (git checkout -b feature/AmazingFeature)
Commit tus cambios (git commit -m 'Add some AmazingFeature')
Push a la rama (git push origin feature/AmazingFeature)
Abre un Pull Request
ğŸ“§ Contacto
Tu Nombre - tu-email@example.com

Link del Proyecto: https://github.com/tu-usuario/ia-faces-classification

ğŸ™ Agradecimientos
Dataset proporcionado por philosopher0808 en Kaggle
FFHQ dataset por NVIDIA Research
Comunidad de TensorFlow/PyTorch por recursos educativos
<div align="center"> <p>Hecho con â¤ï¸ para la detecciÃ³n de deepfakes</p> <p>â­ Si este proyecto te ha sido Ãºtil, considera darle una estrella</p> </div>
